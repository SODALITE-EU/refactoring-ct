{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to train PeakLens optimized model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"PeakLens_optimized\"\n",
    "DATASET_PATH = \"/data/skyline-extraction-patches-dataset\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=x,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    conv2 = tf.layers.separable_conv2d(\n",
    "        inputs=conv1,\n",
    "        filters=32,\n",
    "        kernel_size=[3, 3],\n",
    "        strides=(2, 2),\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    conv3 = tf.layers.separable_conv2d(\n",
    "        inputs=conv2,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    conv4 = tf.layers.separable_conv2d(\n",
    "        inputs=conv3,\n",
    "        filters=64,\n",
    "        kernel_size=[3, 3],\n",
    "        strides=(2, 2),\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    conv5 = tf.layers.separable_conv2d(\n",
    "        inputs=conv4,\n",
    "        filters=128,\n",
    "        kernel_size=[3, 3],\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    conv6 = tf.layers.conv2d(\n",
    "        inputs=conv5, \n",
    "        filters=2, \n",
    "        kernel_size=[3,3])\n",
    "\n",
    "    output = tf.reshape(conv6, [-1, 1 * 1 * 2])\n",
    "\n",
    "    softmax = tf.nn.softmax(output, name=\"softmax_tensor\")\n",
    "\n",
    "    return output, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_label(path, label):\n",
    "    image = tf.read_file(path)\n",
    "    image_decoded = tf.image.decode_jpeg(image)\n",
    "    image_decoded = tf.image.random_flip_left_right(image_decoded)    \n",
    "    return image_decoded, label\n",
    "\n",
    "def get_dataset_split(split):\n",
    "    positive_paths = glob.glob(\"{}/{}/patches/positive/*.jpg\".format(DATASET_PATH, split))\n",
    "    negative_paths = glob.glob(\"{}/{}/patches/negative/*.jpg\".format(DATASET_PATH, split))\n",
    "  \n",
    "    positive_labels = [1] * len(positive_paths)\n",
    "    negative_labels = [0] * len(negative_paths)\n",
    "  \n",
    "    paths = positive_paths + negative_paths\n",
    "    labels = positive_labels + negative_labels\n",
    "\n",
    "    tf_paths = tf.constant(paths)\n",
    "    tf_labels = tf.constant(labels)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((tf_paths, tf_labels))\n",
    "    dataset = dataset.map(load_image_and_label, num_parallel_calls=multiprocessing.cpu_count())\\\n",
    "        .shuffle(len(paths)).batch(BATCH_SIZE).repeat(EPOCHS).prefetch(2)\n",
    "    return dataset, len(paths)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    512\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    978\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype string for Tensor with dtype float32: 'Tensor(\"arg0:0\", shape=(), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-33100b36604f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training split loaded ({:,} images).\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation split loaded ({:,} images).\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c79f5555f6dc>\u001b[0m in \u001b[0;36mget_dataset_split\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image_and_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1582\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1583\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1584\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2770\u001b[0m     super(ParallelMapDataset, self).__init__(\n\u001b[0;32m-> 2771\u001b[0;31m         input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality)\n\u001b[0m\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality)\u001b[0m\n\u001b[1;32m   2735\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 2737\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, defun_kwargs)\u001b[0m\n\u001b[1;32m   2122\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2124\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m       \u001b[0;31m# Use the private method that will execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    488\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;31m# Adds this function into 'g'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_by_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_caller_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         whitelisted_stateful_ops=self._whitelisted_stateful_ops)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref, arg_shapes, whitelisted_stateful_ops)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;31m# Call func and gather the output tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c79f5555f6dc>\u001b[0m in \u001b[0;36mload_image_and_label\u001b[0;34m(path, label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image_and_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_flip_left_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_decoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_decoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    587\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 589\u001b[0;31m         \"ReadFile\", filename=filename, name=name)\n\u001b[0m\u001b[1;32m    590\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_INVALID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m               raise TypeError(\"%s expected type of %s.\" %\n\u001b[0;32m--> 534\u001b[0;31m                               (prefix, dtypes.as_dtype(input_arg.type).name))\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m               \u001b[0;31m# Update the maps with the default, if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "training_dataset, training_steps = get_dataset_split(\"training\")\n",
    "print(\"Training split loaded ({:,} images).\".format(training_steps*BATCH_SIZE))\n",
    "\n",
    "validation_dataset, validation_steps = get_dataset_split(\"validation\")\n",
    "print(\"Validation split loaded ({:,} images).\".format(validation_steps*BATCH_SIZE))\n",
    "\n",
    "test_dataset, test_steps = get_dataset_split(\"testing\")\n",
    "print(\"Test split loaded ({:,} images).\".format(test_steps*BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 20,578.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Build the graph for the deep net\n",
    "x = tf.placeholder(tf.float32, [None, 29, 29, 3])\n",
    "y_ = tf.placeholder(tf.int64, [None])\n",
    "y_conv, softmax = deepnn(x)\n",
    "\n",
    "print(\"Parameters: {:,}.\".format(np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss, adam_optimizer, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cross entropy as cost function\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=y_, logits=y_conv)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Set Adam optimizer as trainer\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "\n",
    "# Evaluation\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), y_)\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to visualize the training with tensorboard by executing the following command with the corresponding logdir path\n",
    "\n",
    "tensorboard --logdir=graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training.\n",
      "Epoch 0, training accuracy: 0.940754\n",
      "Epoch 0, validation accuracy: 0.954395\n",
      "Epoch 0, validation error 0.122062 - session saved\n",
      "Epoch 1, training accuracy: 0.956603\n",
      "Epoch 1, validation accuracy: 0.958634\n",
      "Epoch 1, validation error 0.113437 - session saved\n",
      "Epoch 2, training accuracy: 0.960124\n",
      "Epoch 2, validation accuracy: 0.961347\n",
      "Epoch 2, validation error 0.107196 - session saved\n",
      "Epoch 3, training accuracy: 0.961666\n",
      "Epoch 3, validation accuracy: 0.961418\n",
      "Epoch 3, validation error 0.104961 - session saved\n",
      "Epoch 4, training accuracy: 0.962832\n",
      "Epoch 4, validation accuracy: 0.96282\n",
      "Epoch 4, validation error 0.102163 - session saved\n",
      "Epoch 5, training accuracy: 0.963649\n",
      "Epoch 5, validation accuracy: 0.963092\n",
      "Epoch 5, validation error 0.101458 - session saved\n",
      "Epoch 6, training accuracy: 0.96421\n",
      "Epoch 6, validation accuracy: 0.96228\n",
      "Epoch 7, training accuracy: 0.964582\n",
      "Epoch 7, validation accuracy: 0.963947\n",
      "Epoch 7, validation error 0.0991454 - session saved\n",
      "Epoch 8, training accuracy: 0.965075\n",
      "Epoch 8, validation accuracy: 0.962123\n",
      "Epoch 9, training accuracy: 0.965167\n",
      "Epoch 9, validation accuracy: 0.963993\n",
      "Epoch 9, validation error 0.0985859 - session saved\n",
      "Epoch 10, training accuracy: 0.965696\n",
      "Epoch 10, validation accuracy: 0.963706\n",
      "Epoch 11, training accuracy: 0.965807\n",
      "Epoch 11, validation accuracy: 0.963837\n",
      "Epoch 12, training accuracy: 0.965975\n",
      "Epoch 12, validation accuracy: 0.962366\n",
      "Epoch 13, training accuracy: 0.966108\n",
      "Epoch 13, validation accuracy: 0.963202\n",
      "Epoch 14, training accuracy: 0.966408\n",
      "Epoch 14, validation accuracy: 0.964082\n",
      "Epoch 15, training accuracy: 0.966671\n",
      "Epoch 15, validation accuracy: 0.963511\n",
      "Epoch 16, training accuracy: 0.966577\n",
      "Epoch 16, validation accuracy: 0.963096\n",
      "Epoch 17, training accuracy: 0.966906\n",
      "Epoch 17, validation accuracy: 0.964479\n",
      "Epoch 17, validation error 0.0984369 - session saved\n",
      "Epoch 18, training accuracy: 0.967062\n",
      "Epoch 18, validation accuracy: 0.96396\n",
      "Epoch 19, training accuracy: 0.967138\n",
      "Epoch 19, validation accuracy: 0.963623\n",
      "Epoch 20, training accuracy: 0.967311\n",
      "Epoch 20, validation accuracy: 0.965345\n",
      "Epoch 20, validation error 0.0961657 - session saved\n",
      "Epoch 21, training accuracy: 0.967473\n",
      "Epoch 21, validation accuracy: 0.96438\n",
      "Epoch 22, training accuracy: 0.967521\n",
      "Epoch 22, validation accuracy: 0.963036\n",
      "Epoch 23, training accuracy: 0.967564\n",
      "Epoch 23, validation accuracy: 0.964602\n",
      "Epoch 24, training accuracy: 0.967603\n",
      "Epoch 24, validation accuracy: 0.964954\n",
      "Epoch 25, training accuracy: 0.967776\n",
      "Epoch 25, validation accuracy: 0.964555\n",
      "Epoch 26, training accuracy: 0.967687\n",
      "Epoch 26, validation accuracy: 0.964285\n",
      "Epoch 27, training accuracy: 0.967897\n",
      "Epoch 27, validation accuracy: 0.964258\n",
      "Epoch 28, training accuracy: 0.967832\n",
      "Epoch 28, validation accuracy: 0.964637\n",
      "Epoch 29, training accuracy: 0.968003\n",
      "Epoch 29, validation accuracy: 0.963907\n",
      "Epoch 30, training accuracy: 0.96782\n",
      "Epoch 30, validation accuracy: 0.964768\n",
      "Training finished in epoch 30 due to early stopping.\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #Saver to save the best epoch (the one with lowest error)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    #Visualize on Tensorboard\n",
    "    train_writer = tf.summary.FileWriter('./graphs/{}/train'.format(MODEL_NAME), sess.graph)\n",
    "    validation_writer = tf.summary.FileWriter('./graphs/{}/validation'.format(MODEL_NAME), sess.graph)\n",
    "\n",
    "    #Prepare iterator for the dataset\n",
    "    training_iterator = training_dataset.make_one_shot_iterator()\n",
    "    next_training_batch = training_iterator.get_next()\n",
    "\n",
    "    validation_iterator = validation_dataset.make_one_shot_iterator()\n",
    "    next_validation_batch = validation_iterator.get_next()\n",
    "\n",
    "    print(\"Started training.\")\n",
    "    min_validation_loss = sys.maxint\n",
    "    epochs_without_improvement = 0 # to determine whether early stopping is reached\n",
    "    \n",
    "    for epoch_i in range(EPOCHS):\n",
    "        training_losses = []\n",
    "        training_accuracies = []\n",
    "        for i in range(training_steps):\n",
    "            batch = sess.run(next_training_batch)\n",
    "\n",
    "            accuracy_val, loss_val  = sess.run([accuracy, cross_entropy], feed_dict={x: batch[0], y_: batch[1]})\n",
    "            training_accuracies.append(accuracy_val)\n",
    "            training_losses.append(loss_val)\n",
    "            \n",
    "            train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "            \n",
    "        epoch_accuracy = np.mean(training_accuracies)\n",
    "        epoch_loss = np.mean(training_losses)\n",
    "        \n",
    "        print('Epoch %d, training accuracy: %g' % (epoch_i, epoch_accuracy))\n",
    "        summary = tf.Summary()\n",
    "        summary.value.add(tag=\"accuracy\", simple_value=epoch_accuracy)\n",
    "        summary.value.add(tag=\"loss\", simple_value=epoch_loss)\n",
    "        train_writer.add_summary(summary, global_step=epoch_i)\n",
    "\n",
    "        validation_accuracies = []\n",
    "        validation_losses = []\n",
    "        for j in range(validation_steps):\n",
    "            batch = sess.run(next_validation_batch)\n",
    "\n",
    "            accuracy_val, loss_val = sess.run([accuracy, cross_entropy], feed_dict={x: batch[0], y_: batch[1]})\n",
    "            validation_accuracies.append(accuracy_val)\n",
    "            validation_losses.append(loss_val)\n",
    "            \n",
    "        epoch_accuracy = np.mean(validation_accuracies)\n",
    "        epoch_loss = np.mean(validation_losses)        \n",
    "\n",
    "        print('Epoch %d, validation accuracy: %g' % (epoch_i, epoch_accuracy))\n",
    "        summary = tf.Summary()\n",
    "        summary.value.add(tag=\"accuracy\", simple_value=epoch_accuracy)\n",
    "        summary.value.add(tag=\"loss\", simple_value=epoch_loss)\n",
    "        validation_writer.add_summary(summary, global_step=epoch_i)\n",
    "\n",
    "        if(epoch_loss < min_validation_loss):\n",
    "            min_validation_loss = epoch_loss\n",
    "            epochs_without_improvement = 0\n",
    "            print('Epoch %d, validation loss %g - session saved' % (epoch_i, min_validation_loss))\n",
    "            saver.save(sess, \"./checkpoint/{}.ckpt\".format(MODEL_NAME))\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement == EARLY_STOPPING:\n",
    "                print('Training finished in epoch %d due to early stopping.' % epoch_i)\n",
    "                break\n",
    "    print('Finished training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/PeakLens_optimized.ckpt\n",
      "Started test.\n",
      "Test accuracy: 0.963755\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # Restore the best session\n",
    "    saver.restore(sess, \"./checkpoint/{}.ckpt\".format(MODEL_NAME))\n",
    "    \n",
    "    # Compute test accuracy\n",
    "    test_accuracies = []\n",
    "    test_iterator = test_dataset.make_one_shot_iterator()\n",
    "    next_test_batch = test_iterator.get_next()\n",
    "    print(\"Started test.\")\n",
    "    for i in range(test_steps):\n",
    "        batch = sess.run(next_test_batch)\n",
    "        accuracy_val = sess.run([accuracy], feed_dict={x: batch[0], y_: batch[1]})\n",
    "        test_accuracies.append(accuracy_val)\n",
    "\n",
    "    print('Test accuracy: %g' % np.mean(test_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/PeakLens_optimized.ckpt\n",
      "INFO:tensorflow:Froze 16 variables.\n",
      "INFO:tensorflow:Converted 16 variables to const ops.\n",
      "Converted model to pb.\n",
      "INFO:tensorflow:./export2/00000123-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define input size dimensions for complete images\n",
    "x = tf.placeholder(tf.float32, [1, 240, 320, 3])\n",
    "y_conv, softmax = deepnn(x)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if not os.path.exists('./protobufs/'):\n",
    "    os.makedir('./protobufs/')\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"./checkpoint/{}.ckpt\".format(MODEL_NAME))\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [\"softmax_tensor\"])\n",
    "    \n",
    "    with tf.gfile.GFile(\"./protobufs/{}.pb\".format(MODEL_NAME), \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "        print('Converted model to pb.')\n",
    "    \n",
    "    export = exporter.Exporter(tf.train.Saver())\n",
    "    export.init(named_graph_signatures={\n",
    "        \"inputs\": exporter.generic_signature({\"input\": x}),\n",
    "        \"outputs\": exporter.generic_signature({\"output\": softmax})\n",
    "        #\"regress\": exporter.regression_signature(x, y)\n",
    "    })\n",
    "    export.export('./export/', tf.constant(123), sess)\n",
    "    \n",
    "    tf.saved_model.simple_save(sesh,\n",
    "            './export-pb/',\n",
    "            inputs={\"input\": input_node},\n",
    "            outputs={\"output\": net.get_output()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
